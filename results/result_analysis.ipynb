{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "The objective of this notebook is to load and analyse the results stored in the result folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the data for all quantization levels\n",
    "\n",
    "all_quantization_list = [4, 8, 16]\n",
    "\n",
    "# Dictionary to store all calculated metrics for each quantization\n",
    "processed_metrics = {}\n",
    "\n",
    "# Loop through each quantization level (4, 8, 16 bits)\n",
    "for bits in all_quantization_list:\n",
    "    # Load the data\n",
    "    with Path(\"result_\" + str(bits) + \"bit_1000_examples.json\").open() as f:\n",
    "        current_results = json.load(f)\n",
    "\n",
    "    # Initialize accumulators for the current bit case\n",
    "    total_examples = 0\n",
    "    total_weighted_accuracy_sum = 0\n",
    "    total_execution_time = 0\n",
    "    max_vram = 0\n",
    "\n",
    "    # Iterate through the subjects' data for the current quantization case\n",
    "    for data in current_results.values():\n",
    "        num_examples = data[\"number_examples\"]\n",
    "        accuracy = data[\"accuracy\"]\n",
    "        execution_time = data[\"execution_time\"]\n",
    "        used_vram = data[\"used_VRAM\"]\n",
    "\n",
    "        total_examples += num_examples\n",
    "        total_weighted_accuracy_sum += num_examples * accuracy\n",
    "        total_execution_time += execution_time\n",
    "\n",
    "        max_vram = max(used_vram, max_vram)\n",
    "\n",
    "    # Calculate the final metrics for the current bit case\n",
    "    mean_acc = total_weighted_accuracy_sum / total_examples\n",
    "    time_per_item = total_execution_time / total_examples\n",
    "\n",
    "    # Store the calculated metrics in the 'processed_metrics' dictionary\n",
    "    processed_metrics[bits] = {\n",
    "        \"total_examples\": total_examples,\n",
    "        \"max_vram\": max_vram,\n",
    "        \"mean_accuracy\": mean_acc,\n",
    "        \"time_per_item\": time_per_item,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results for each quantization level\n",
    "for bits, metrics in processed_metrics.items():\n",
    "    print(f\"\\n--- Results for {bits}-bit Quantization ---\")\n",
    "    print(f\"Total examples: {metrics['total_examples']}\")\n",
    "    print(f\"Maximum VRAM used: {metrics['max_vram']} MB\")\n",
    "    print(f\"Mean weighted accuracy: {metrics['mean_accuracy'] * 100:.3f} %\")\n",
    "    print(f\"Average time per item: {metrics['time_per_item']:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corrupt_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
